import streamlit as st
from openai import OpenAI

st.set_page_config(layout="wide")  # ConfiguraÃ§Ã£o para layout de pÃ¡gina amplo

# Inicialize o cliente OpenAI
client = OpenAI(
    api_key="LL-rZdxy5UFL4evTVeC6H1Jzuph00H08neiKQUGm3HSYOm1qMD4T8YxonRYedIH6856",
    base_url="https://api.llama-api.com"
)

# HistÃ³rico de conversa
conversation_history = []

# FunÃ§Ã£o para enviar mensagem e obter resposta
def enviar_mensagem(pergunta):
    # Enviar a mensagem para a IA e obter a resposta
    response = client.chat.completions.create(
        model="llama-13b-chat",
        messages=[
            {"role": "system", "content": "OlÃ¡! Sou um especialista em Python, Pandas, PySpark e AWS."},
            {"role": "user", "content": pergunta}
        ]
    )
    return response.choices[0].message.content

# Interface Streamlit para envio de pergunta
pergunta = st.chat_input("Digite sua pergunta para a IA e pressione Enter:")

# Enviar a pergunta para a IA quando o usuÃ¡rio pressionar Enter
if pergunta:
    # Adicionar a pergunta ao histÃ³rico de conversa
    conversation_history.append(("ğŸ™â€â™‚ï¸:", pergunta))
    # Envie a pergunta para a IA e obtenha a resposta
    resposta = enviar_mensagem(pergunta)
    # Adicionar a resposta ao histÃ³rico de conversa
    conversation_history.append(("ğŸ¤–:", resposta))

# Barra lateral
st.sidebar.title("ğŸ¦™ LLAMA 2")  # TÃ­tulo na barra lateral
# Adicionando uma descriÃ§Ã£o na barra lateral
st.sidebar.markdown("Este Ã© um projeto feito utilizando o ğŸ¦™ LLAMA 2.")

st.title("Chat com OpenAI")

# Exibir histÃ³rico de conversa
st.subheader("HistÃ³rico de Conversa")
for role, message in conversation_history:
    st.write(role, message)
